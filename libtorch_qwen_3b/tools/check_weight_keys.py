# ä¿å­˜ä¸º check_weight_keys.py
import torch
from safetensors.torch import load_file

# ä½ çš„safetensorsè·¯å¾„
SAFETENSORS_PATH = "/home/aoi/new/resume/Dev_container/hunyuan_model/qwen2.5-0.5b-instruct/model.safetensors"

# åŠ è½½æƒé‡å¹¶æ‰“å°æ‰€æœ‰é”®å
state_dict = load_file(SAFETENSORS_PATH, device="cpu")
print(f"æƒé‡æ€»æ•°ï¼š{len(state_dict)}")
print("\næ‰€æœ‰æƒé‡é”®åï¼ˆå‰20ä¸ª+åŒ…å«embedding/lm_head/wteçš„é”®åï¼‰ï¼š")

# æ‰“å°å‰20ä¸ªé”®å
for i, (key, _) in enumerate(state_dict.items()):
    if i < 20:
        print(f"  {key}")
    # ç­›é€‰åŒ…å«å…³é”®è¯çš„é”®åï¼ˆæ‰¾åˆ°Embeddingå’ŒLMHeadï¼‰
    if any(k in key.lower() for k in ["embedding", "wte", "lm_head", "lmhead"]):
        print(f"ğŸ” å…³é”®æƒé‡ï¼š{key}")

# è‹¥ä¸Šè¿°ç­›é€‰æœªæ‰¾åˆ°ï¼Œç›´æ¥æ‰“å°æ‰€æœ‰åŒ…å«"weight"çš„é”®å
print("\næ‰€æœ‰åŒ…å«'weight'çš„é”®åï¼ˆç­›é€‰å…³é”®æƒé‡ï¼‰ï¼š")
for key, _ in state_dict.items():
    if "weight" in key:
        print(f"  {key}")
