#include "../include/qwen_model.h"
#include "../include/qwen_env.h"
#include "../include/qwen_model_config.h"
#include <iostream>
#include <vector>
#include <chrono>

// é…ç½®Qwenæ¨¡å‹å‚æ•°ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
const auto& QWEN_CFG = qwen::get_model_config();
const std::string WEIGHT_PATH = qwen::get_weight_path();
const std::string TOKENIZER_SCRIPT = qwen::get_tokenizer_script();
const std::string TOKENIZER_MODEL_DIR = qwen::get_tokenizer_model_dir();
const std::string PYTHON_CMD = qwen::get_python_cmd();

// ç¼–ç æ–‡æœ¬ä¸ºtoken IDs
std::vector<int64_t> encode_text(const std::string& text) {
    std::string cmd = PYTHON_CMD + " " + TOKENIZER_SCRIPT + " \"" + text + "\" 2>/dev/null";
    
    FILE* pipe = popen(cmd.c_str(), "r");
    if (!pipe) {
        throw std::runtime_error("æ— æ³•æ‰§è¡Œåˆ†è¯å‘½ä»¤");
    }
    
    char buffer[4096];
    std::string result;
    while (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
        result += buffer;
    }
    pclose(pipe);
    
    // è§£æJSONæ ¼å¼çš„token IDs
    std::vector<int64_t> token_ids;
    size_t start = result.find("[");
    size_t end = result.find("]");
    if (start != std::string::npos && end != std::string::npos) {
        std::string ids_str = result.substr(start + 1, end - start - 1);
        std::stringstream ss(ids_str);
        std::string item;
        while (std::getline(ss, item, ',')) {
            token_ids.push_back(std::stoll(item));
        }
    }
    
    return token_ids;
}

// æ‰“å°å¼ é‡ä¿¡æ¯
void print_tensor_info(const std::string& tensor_name, const torch::Tensor& tensor) {
    std::cout << "\n" << tensor_name << "ï¼š" << std::endl;
    std::cout << "  å½¢çŠ¶ï¼š" << tensor.sizes() << std::endl;
    std::cout << "  æ•°æ®ç±»å‹ï¼š" << tensor.dtype().name() << std::endl;
    std::cout << "  è®¾å¤‡ï¼š" << tensor.device() << std::endl;
    if (tensor.numel() > 0 && tensor.numel() <= 10) {
        std::cout << "  å€¼ï¼š" << tensor.flatten() << std::endl;
    } else if (tensor.numel() > 0) {
        int64_t print_size = std::min(5L, tensor.numel());
        std::cout << "  å‰" << print_size << "ä¸ªå…ƒç´ ï¼š" << tensor.flatten().slice(0, 0, print_size) << std::endl;
    }
}

// è§£ç å•ä¸ªtoken IDä¸ºæ–‡æœ¬
std::string decode_token(int64_t token_id) {
    std::string cmd = PYTHON_CMD + " -c \"from transformers import AutoTokenizer; tokenizer = AutoTokenizer.from_pretrained('" + TOKENIZER_MODEL_DIR + "', trust_remote_code=True); print(tokenizer.decode([" + std::to_string(token_id) + "]), end='')\" 2>/dev/null";
    
    FILE* pipe = popen(cmd.c_str(), "r");
    if (!pipe) return "[è§£ç å¤±è´¥]";
    
    char buffer[1024];
    std::string result;
    while (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
        result += buffer;
    }
    pclose(pipe);
    
    return result.empty() ? "[ç©º]" : result;
}

// è§£ç å¤šä¸ªtoken IDsä¸ºæ–‡æœ¬
std::string decode_tokens(const std::vector<int64_t>& token_ids) {
    if (token_ids.empty()) return "[ç©º]";
    
    std::string ids_str = "[";
    for (size_t i = 0; i < token_ids.size(); ++i) {
        ids_str += std::to_string(token_ids[i]);
        if (i < token_ids.size() - 1) ids_str += ",";
    }
    ids_str += "]";
    
    std::string cmd = PYTHON_CMD + " -c \"from transformers import AutoTokenizer; tokenizer = AutoTokenizer.from_pretrained('" + TOKENIZER_MODEL_DIR + "', trust_remote_code=True); print(tokenizer.decode(" + ids_str + "), end='')\" 2>/dev/null";
    
    FILE* pipe = popen(cmd.c_str(), "r");
    if (!pipe) return "[è§£ç å¤±è´¥]";
    
    char buffer[1024];
    std::string result;
    while (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
        result += buffer;
    }
    pclose(pipe);
    
    return result.empty() ? "[ç©º]" : result;
}

int main() {
    std::cout << std::string(70, '=') << std::endl;
    std::cout << "=== Qwen 2.5 æ¨¡å‹ç®€åŒ–æµ‹è¯•ï¼ˆä»…å‰å‘ä¼ æ’­ï¼‰===" << std::endl;
    std::cout << std::string(70, '=') << std::endl;

    try {
        qwen::ensure_required_paths(WEIGHT_PATH, TOKENIZER_SCRIPT, TOKENIZER_MODEL_DIR);
    } catch (const std::exception& e) {
        std::cerr << "âŒ è·¯å¾„é…ç½®é”™è¯¯: " << e.what() << std::endl;
        return 1;
    }
    
    // 1. åˆå§‹åŒ–è®¾å¤‡
    torch::Device device = torch::kCPU;
    if (torch::cuda::is_available()) {
        device = torch::Device(torch::kCUDA, 0);
        std::cout << "âœ… ä½¿ç”¨CUDAè®¾å¤‡" << std::endl;
    } else {
        std::cout << "â„¹ï¸ ä½¿ç”¨CPUè®¾å¤‡" << std::endl;
    }

    // 2. åˆå§‹åŒ–æ¨¡å‹
    std::cout << "\nåˆå§‹åŒ–Qwenæ¨¡å‹..." << std::endl;
    QwenModel model = QwenModel(
        QWEN_CFG.vocab_size,
        QWEN_CFG.hidden_size,
        QWEN_CFG.num_layers,
        QWEN_CFG.num_heads,
        QWEN_CFG.num_kv_heads,
        QWEN_CFG.intermediate_size,
        QWEN_CFG.max_position_embeddings,
        QWEN_CFG.rope_theta,
        QWEN_CFG.rms_norm_eps,
        QWEN_CFG.bos_token_id,
        QWEN_CFG.eos_token_id
    );
    model->eval();
    std::cout << "âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆ" << QWEN_CFG.num_layers << "å±‚ Transformerï¼‰" << std::endl;

    // 3. åŠ è½½æƒé‡
    std::cout << "\nå¼€å§‹åŠ è½½æƒé‡..." << std::endl;
    auto start_load = std::chrono::high_resolution_clock::now();
    model->load_weights(WEIGHT_PATH);
    auto end_load = std::chrono::high_resolution_clock::now();
    auto load_time = std::chrono::duration_cast<std::chrono::seconds>(end_load - start_load).count();
    std::cout << "æƒé‡åŠ è½½è€—æ—¶: " << load_time << " ç§’" << std::endl;
    
    // 4. ç§»åŠ¨åˆ°è®¾å¤‡
    std::cout << "\nå°†æ¨¡å‹ç§»åŠ¨åˆ° " << device << "..." << std::endl;
    model->to(device, torch::kBFloat16);
    std::cout << "âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡" << std::endl;

    std::cout << "\n" << std::string(70, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•1ï¼šä¸­æ–‡æ–‡æœ¬å‰å‘ä¼ æ’­ã€‘" << std::endl;
    std::cout << std::string(70, '=') << std::endl;

    // æµ‹è¯•1ï¼šä¸­æ–‡æ–‡æœ¬
    {
        std::string input_text = "ä½ å¥½";
        std::cout << "\nè¾“å…¥æ–‡æœ¬: \"" << input_text << "\"" << std::endl;
        
        std::vector<int64_t> tokens = encode_text(input_text);
        std::cout << "Token IDs: [";
        for (size_t i = 0; i < tokens.size(); ++i) {
            std::cout << tokens[i];
            if (i < tokens.size() - 1) std::cout << ", ";
        }
        std::cout << "]" << std::endl;
        
        torch::Tensor input_ids = torch::from_blob(
            tokens.data(), 
            {1, static_cast<long>(tokens.size())}, 
            torch::kInt64
        ).clone().to(device);
        
        print_tensor_info("è¾“å…¥Tensor", input_ids);
        
        torch::NoGradGuard no_grad;
        auto start = std::chrono::high_resolution_clock::now();
        torch::Tensor logits = model->forward(input_ids, false);
        auto end = std::chrono::high_resolution_clock::now();

        print_tensor_info("è¾“å‡ºlogits", logits);
        
        // è·å–é¢„æµ‹çš„token
        int64_t pred_token = logits[0][-1].argmax().item<int64_t>();
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtoken ID: " << pred_token << std::endl;
        std::string pred_text = decode_token(pred_token);
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtokenæ–‡æœ¬: \"" << pred_text << "\"" << std::endl;
        std::cout << "è€—æ—¶: " << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count() << " ms\n";
    }

    std::cout << "\n" << std::string(70, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•2ï¼šæ›´é•¿çš„ä¸­æ–‡æ–‡æœ¬ã€‘" << std::endl;
    std::cout << std::string(70, '=') << std::endl;

    // æµ‹è¯•2ï¼šæ›´é•¿çš„ä¸­æ–‡æ–‡æœ¬
    {
        std::string input_text = "äººå·¥æ™ºèƒ½çš„æœªæ¥";
        std::cout << "\nè¾“å…¥æ–‡æœ¬: \"" << input_text << "\"" << std::endl;
        
        std::vector<int64_t> tokens = encode_text(input_text);
        std::cout << "Token IDs: [";
        for (size_t i = 0; i < tokens.size(); ++i) {
            std::cout << tokens[i];
            if (i < tokens.size() - 1) std::cout << ", ";
        }
        std::cout << "]" << std::endl;
        
        torch::Tensor input_ids = torch::from_blob(
            tokens.data(), 
            {1, static_cast<long>(tokens.size())}, 
            torch::kInt64
        ).clone().to(device);
        
        torch::NoGradGuard no_grad;
        auto start = std::chrono::high_resolution_clock::now();
        torch::Tensor logits = model->forward(input_ids, false);
        auto end = std::chrono::high_resolution_clock::now();

        print_tensor_info("è¾“å‡ºlogits", logits);
        
        // è·å–é¢„æµ‹çš„token
        int64_t pred_token = logits[0][-1].argmax().item<int64_t>();
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtoken ID: " << pred_token << std::endl;
        std::string pred_text = decode_token(pred_token);
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtokenæ–‡æœ¬: \"" << pred_text << "\"" << std::endl;
    }

    std::cout << "\n" << std::string(70, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•3ï¼šä½¿ç”¨KVç¼“å­˜çš„å¤šæ­¥æ¨ç†ã€‘" << std::endl;
    std::cout << std::string(70, '=') << std::endl;

    // æµ‹è¯•3ï¼šåˆ†æ­¥æ¨ç†æ¨¡æ‹Ÿè‡ªå›å½’
    {
        // Step 1: Prefill - å¤„ç†åˆå§‹åºåˆ—
        std::string input_text = "ä»Šå¤©å¤©æ°”";
        std::cout << "\nè¾“å…¥æ–‡æœ¬: \"" << input_text << "\"" << std::endl;
        
        std::vector<int64_t> init_tokens = encode_text(input_text);
        std::cout << "Token IDs: [";
        for (size_t i = 0; i < init_tokens.size(); ++i) {
            std::cout << init_tokens[i];
            if (i < init_tokens.size() - 1) std::cout << ", ";
        }
        std::cout << "]" << std::endl;
        
        torch::Tensor input_ids = torch::from_blob(
            init_tokens.data(), 
            {1, static_cast<long>(init_tokens.size())}, 
            torch::kInt64
        ).clone().to(device);
        
        std::cout << "\nStep 1: Prefillé˜¶æ®µ (" << init_tokens.size() << "ä¸ªtokens)" << std::endl;
        print_tensor_info("è¾“å…¥Tensor", input_ids);
        
        torch::NoGradGuard no_grad;
        auto start1 = std::chrono::high_resolution_clock::now();
        torch::Tensor logits1 = model->forward(input_ids, true);  // use_cache=true
        auto end1 = std::chrono::high_resolution_clock::now();
        
        int64_t next_token = logits1[0][-1].argmax().item<int64_t>();
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtoken ID: " << next_token << std::endl;
        std::string next_text = decode_token(next_token);
        std::cout << "é¢„æµ‹tokenæ–‡æœ¬: \"" << next_text << "\"" << std::endl;
        std::cout << "Prefillè€—æ—¶: " << std::chrono::duration_cast<std::chrono::milliseconds>(end1 - start1).count() << " ms\n";
        
        // Step 2: Decode - ä½¿ç”¨KVç¼“å­˜å¤„ç†å•ä¸ªtoken
        std::cout << "\nStep 2: Decodeé˜¶æ®µ (1ä¸ªtokenï¼Œä½¿ç”¨KVç¼“å­˜)" << std::endl;
        std::vector<int64_t> next_tokens = {next_token};
        torch::Tensor next_input = torch::from_blob(
            next_tokens.data(), 
            {1, 1}, 
            torch::kInt64
        ).clone().to(device);
        
        print_tensor_info("è¾“å…¥Tensor", next_input);
        std::cout << "è¾“å…¥tokenæ–‡æœ¬: \"" << next_text << "\"" << std::endl;
        
        auto start2 = std::chrono::high_resolution_clock::now();
        torch::Tensor logits2 = model->forward(next_input, true);  // use_cache=trueç»§ç»­ä½¿ç”¨ç¼“å­˜
        auto end2 = std::chrono::high_resolution_clock::now();
        
        int64_t next_token2 = logits2[0][0].argmax().item<int64_t>();
        std::cout << "é¢„æµ‹ä¸‹ä¸€ä¸ªtoken ID: " << next_token2 << std::endl;
        std::string next_text2 = decode_token(next_token2);
        std::cout << "é¢„æµ‹tokenæ–‡æœ¬: \"" << next_text2 << "\"" << std::endl;
        std::cout << "Decodeè€—æ—¶: " << std::chrono::duration_cast<std::chrono::milliseconds>(end2 - start2).count() << " ms";
        std::cout << " (åº”è¯¥æ¯”Prefillå¿«å¾—å¤š)\n";
        
        // æ˜¾ç¤ºå®Œæ•´ç”Ÿæˆåºåˆ—
        std::cout << "\nå®Œæ•´ç”Ÿæˆåºåˆ—: \"" << input_text << next_text << next_text2 << "\"" << std::endl;
        
        // æ¸…é™¤ç¼“å­˜
        model->clear_cache();
        std::cout << "\nâœ… KVç¼“å­˜å·²æ¸…é™¤" << std::endl;
    }

    std::cout << "\n" << std::string(70, '=') << std::endl;
    std::cout << "ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼æ¨¡å‹å·¥ä½œæ­£å¸¸" << std::endl;
    std::cout << std::string(70, '=') << std::endl;
    
    return 0;
}
