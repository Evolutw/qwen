#include "../include/qwen_transformer_block.h"
#include "../include/qwen_embedding.h"
#include "../include/qwen_env.h"
#include "../include/qwen_model_config.h"
#include <iostream>
#include <vector>

// é…ç½®Qwenæ¨¡å‹å‚æ•°ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
const auto& QWEN_CFG = qwen::get_model_config();
const std::string WEIGHT_PATH = qwen::get_weight_path();

// æ‰“å°å¼ é‡ä¿¡æ¯
void print_tensor_info(const std::string& tensor_name, const torch::Tensor& tensor) {
    std::cout << "\n" << tensor_name << "ï¼š" << std::endl;
    std::cout << "  å½¢çŠ¶ï¼š" << tensor.sizes() << std::endl;
    std::cout << "  æ•°æ®ç±»å‹ï¼š" << tensor.dtype().name() << std::endl;
    std::cout << "  è®¾å¤‡ï¼š" << tensor.device() << std::endl;
    if (tensor.numel() > 0) {
        int64_t print_size = std::min(5L, tensor.numel());
        std::cout << "  å‰" << print_size << "ä¸ªå…ƒç´ ï¼š" << tensor.flatten().slice(0, 0, print_size) << std::endl;
        
        // æ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…å¯¹æµ®ç‚¹ç±»å‹ï¼‰
        if (tensor.is_floating_point()) {
            std::cout << "  å‡å€¼ï¼š" << tensor.mean().item<float>() << std::endl;
            std::cout << "  æ ‡å‡†å·®ï¼š" << tensor.std().item<float>() << std::endl;
        }
    }
}

int main() {
    std::cout << std::string(60, '=') << std::endl;
    std::cout << "=== Qwen Transformer Blockæµ‹è¯• ===" << std::endl;
    std::cout << std::string(60, '=') << std::endl;

    try {
        qwen::ensure_required_paths(WEIGHT_PATH, qwen::get_tokenizer_script(), qwen::get_tokenizer_model_dir());
    } catch (const std::exception& e) {
        std::cerr << "âŒ è·¯å¾„é…ç½®é”™è¯¯: " << e.what() << std::endl;
        return 1;
    }
    
    // 1. åˆå§‹åŒ–è®¾å¤‡
    torch::Device device = torch::kCPU;
    if (torch::cuda::is_available()) {
        device = torch::Device(torch::kCUDA, 0);
        std::cout << "âœ… ä½¿ç”¨CUDAè®¾å¤‡" << std::endl;
    } else {
        std::cout << "â„¹ï¸ ä½¿ç”¨CPUè®¾å¤‡" << std::endl;
    }

    // 2. åˆå§‹åŒ–Transformer Block (ç¬¬0å±‚)
    QwenTransformerBlock transformer_block = QwenTransformerBlock(
        0,  // layer_idx
        QWEN_CFG.hidden_size,
        QWEN_CFG.num_heads,
        QWEN_CFG.num_kv_heads,
        QWEN_CFG.intermediate_size,
        QWEN_CFG.max_position_embeddings,
        QWEN_CFG.rope_theta,
        QWEN_CFG.rms_norm_eps
    );
    transformer_block->eval();
    std::cout << "âœ… Transformer Blockåˆå§‹åŒ–å®Œæˆ" << std::endl;
    std::cout << "  hidden_size: " << QWEN_CFG.hidden_size << std::endl;
    std::cout << "  intermediate_size: " << QWEN_CFG.intermediate_size << std::endl;
    std::cout << "  num_heads: " << QWEN_CFG.num_heads << std::endl;
    std::cout << "  num_kv_heads: " << QWEN_CFG.num_kv_heads << std::endl;

    // 3. åŠ è½½æƒé‡
    transformer_block->load_weights(WEIGHT_PATH);
    
    // 4. ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è½¬æ¢æ•°æ®ç±»å‹
    transformer_block->to(device, torch::kBFloat16);
    std::cout << "âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡ï¼š" << device << std::endl;

    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•1ï¼šåŸºæœ¬å‰å‘ä¼ æ’­ã€‘" << std::endl;
    std::cout << std::string(60, '=') << std::endl;

    // 5. ç”Ÿæˆæµ‹è¯•è¾“å…¥ï¼ˆæ¨¡æ‹ŸEmbeddingå±‚è¾“å‡ºï¼‰
    int64_t batch_size = 2;
    int64_t seq_len = 4;
    torch::Tensor hidden_states = torch::randn(
        {batch_size, seq_len, QWEN_CFG.hidden_size},
        torch::TensorOptions().dtype(torch::kBFloat16).device(device)
    );
    print_tensor_info("è¾“å…¥hidden_states", hidden_states);

    // 6. å‰å‘ä¼ æ’­
    torch::Tensor output;
    {
        torch::NoGradGuard no_grad;
        output = transformer_block->forward(hidden_states, false);
        print_tensor_info("Transformer Blockè¾“å‡º", output);
    }
    
    // éªŒè¯è¾“å‡ºå½¢çŠ¶
    std::vector<int64_t> expected_shape = {batch_size, seq_len, QWEN_CFG.hidden_size};
    bool shape_match = true;
    for (size_t i = 0; i < expected_shape.size(); ++i) {
        if (output.size(i) != expected_shape[i]) {
            shape_match = false;
            break;
        }
    }
    
    if (shape_match) {
        std::cout << "âœ… Transformer Blockè¾“å‡ºå½¢çŠ¶éªŒè¯é€šè¿‡" << std::endl;
    } else {
        std::cerr << "âŒ Transformer Blockè¾“å‡ºå½¢çŠ¶éªŒè¯å¤±è´¥" << std::endl;
        return 1;
    }

    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•2ï¼šå®Œæ•´æµç¨‹ï¼ˆEmbedding â†’ Transformer Blockï¼‰ã€‘" << std::endl;
    std::cout << std::string(60, '=') << std::endl;

    // 7. åŠ è½½Embeddingå±‚
    QwenEmbedding embedding = QwenEmbedding(QWEN_CFG.vocab_size, QWEN_CFG.hidden_size);
    embedding->eval();
    embedding->load_weights(WEIGHT_PATH);
    embedding->to(device, torch::kBFloat16);
    std::cout << "âœ… Embeddingå±‚å·²åŠ è½½" << std::endl;
    
    // ç”Ÿæˆtoken IDs
    std::vector<int64_t> token_ids = {100, 200, 300, 400};
    torch::Tensor input_ids = torch::tensor(token_ids, torch::kInt64).unsqueeze(0).to(device);
    print_tensor_info("è¾“å…¥Token IDs", input_ids);
    
    // Embedding -> Transformer Block
    {
        torch::NoGradGuard no_grad;
        transformer_block->clear_cache();
        
        torch::Tensor embeddings = embedding->forward(input_ids);
        print_tensor_info("Embeddingè¾“å‡º", embeddings);
        
        torch::Tensor final_output = transformer_block->forward(embeddings, false);
        print_tensor_info("Transformer Blockæœ€ç»ˆè¾“å‡º", final_output);
        
        std::cout << "âœ… å®Œæ•´æµç¨‹æµ‹è¯•æˆåŠŸ" << std::endl;
    }

    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•3ï¼šKVç¼“å­˜åŠŸèƒ½ã€‘" << std::endl;
    std::cout << std::string(60, '=') << std::endl;

    // 8. æµ‹è¯•KVç¼“å­˜
    transformer_block->clear_cache();
    
    // ç¬¬ä¸€æ¬¡ï¼šç¼“å­˜KV
    torch::Tensor first_embeddings = torch::randn(
        {1, 3, QWEN_CFG.hidden_size},
        torch::TensorOptions().dtype(torch::kBFloat16).device(device)
    );
    print_tensor_info("ç¬¬ä¸€æ¬¡è¾“å…¥ (seq_len=3)", first_embeddings);
    
    torch::Tensor first_output;
    {
        torch::NoGradGuard no_grad;
        first_output = transformer_block->forward(first_embeddings, true);
        print_tensor_info("ç¬¬ä¸€æ¬¡è¾“å‡º", first_output);
    }
    
    // ç¬¬äºŒæ¬¡ï¼šä½¿ç”¨ç¼“å­˜
    torch::Tensor second_embeddings = torch::randn(
        {1, 1, QWEN_CFG.hidden_size},
        torch::TensorOptions().dtype(torch::kBFloat16).device(device)
    );
    print_tensor_info("ç¬¬äºŒæ¬¡è¾“å…¥ (seq_len=1, ä½¿ç”¨KVç¼“å­˜)", second_embeddings);
    
    torch::Tensor second_output;
    {
        torch::NoGradGuard no_grad;
        second_output = transformer_block->forward(second_embeddings, true);
        print_tensor_info("ç¬¬äºŒæ¬¡è¾“å‡º", second_output);
    }
    
    std::cout << "\nâœ… KVç¼“å­˜æµ‹è¯•å®Œæˆ" << std::endl;
    std::cout << "  è¯´æ˜: Transformer Blockæ”¯æŒè‡ªå›å½’ç”Ÿæˆæ¨¡å¼" << std::endl;

    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "ã€æµ‹è¯•4ï¼šæ®‹å·®è¿æ¥éªŒè¯ã€‘" << std::endl;
    std::cout << std::string(60, '=') << std::endl;

    // 9. éªŒè¯æ®‹å·®è¿æ¥æ˜¯å¦å·¥ä½œ
    torch::Tensor test_input = torch::randn(
        {1, 2, QWEN_CFG.hidden_size},
        torch::TensorOptions().dtype(torch::kBFloat16).device(device)
    );
    
    torch::Tensor test_output;
    {
        torch::NoGradGuard no_grad;
        transformer_block->clear_cache();
        test_output = transformer_block->forward(test_input, false);
    }
    
    // æ®‹å·®è¿æ¥åº”è¯¥è®©è¾“å‡ºå’Œè¾“å…¥çš„å‡å€¼æ¥è¿‘
    float input_mean = test_input.mean().item<float>();
    float output_mean = test_output.mean().item<float>();
    
    std::cout << "è¾“å…¥å‡å€¼: " << input_mean << std::endl;
    std::cout << "è¾“å‡ºå‡å€¼: " << output_mean << std::endl;
    std::cout << "âœ… æ®‹å·®è¿æ¥å·¥ä½œæ­£å¸¸ï¼ˆè¾“å‡ºåŒ…å«è¾“å…¥çš„ä¿¡æ¯ï¼‰" << std::endl;

    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "ğŸ‰ Qwen Transformer Blockæµ‹è¯•å®Œæˆ" << std::endl;
    std::cout << std::string(60, '=') << std::endl;
    
    return 0;
}
